<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<title>K-Arm Bandits - Learn Reinforcement Learning The fun way</title>
	<meta name="description" content="">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<!-- <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"> -->
	<meta name="viewport" content="width=1024">

	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicon/apple-touch-icon-114x114.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#311e3e">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#311e3e">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#311e3e">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">

</head>

<body>
  <div class="flex-container">
  
<header class="main-header">
  <div class="wrapper">
    <div class="header-flex">
      <div class="menu-icon-container">
        <span class="menu-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
      </div>
      <nav class="main-nav">
        <span class="menu-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
        <ul>
        
          
            <li><a href="/reinforcement/learning/Bandits.html" class="recent-item" ><span>K-Arm Bandits</span></a></li>
          
        
          
            <li><a href="/reinforcement/learning/monteCarlo.html" class="recent-item" ><span>Monte Carlo</span></a></li>
          
        
          
            <li><a href="/reinforcement/learning/dynProg.html" class="recent-item" ><span>Dynamic Programming</span></a></li>
          
        

        </ul>
      </nav>
      <p class="logo"><a href="/">Reinforcement Learning Playground</a></p>
      <div class="search-icon-container">
        <span class="search-icon"><a><i class="fa fa-search" aria-hidden="true"></i></a></span>
      </div>
    </div>
  </div>


  <!-- including plotlyjs -->
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

</header> <!-- End Header -->


  <!-- including mathjax -->
    <script async type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: [
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js",
        "a11y/accessibility-menu.js"
      ],
      jax: ["input/TeX", "output/CommonHTML"],
      TeX: {
        extensions: [
          "AMSmath.js",
          "AMSsymbols.js",
          "noErrors.js",
          "noUndefined.js",
        ]
      }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- Import all the required dependencies -->
  

  

  

  

  

  

  

  <!-- From the web -->
  


  <!-- imported the required visualization script for cover-visualization -->
  <article class="article-page">
    <div class="page-image" style='height: 1100px'>
      <embed id="myFrame" style="background-size: cover;padding: 0%;" frameborder=0 class="cover-image" width="90%" align="middle" padding="0" scrolling="no" src='/assets/viz/bandits/index.html'></embed>
    </div>
    <div class="wrapper">
      <div class="page-content">
        <div class="header-page">
          <h1 class="page-title">K-Arm Bandits</h1>


          <!-- <div class="page-date"><time datetime="2020-07-24 00:00:00 +0530">2020, Jul 24</time></div> -->
        </div>
        <h2 id="um-what-am-i-looking-at">Um.. What am i looking at?</h2>

<p>The Idea Behind this visualization is to give an entire picture of Bandit Algorithm. where we can see all the components, from distribution of each slot machine to Current Expected Rewards.</p>

<p>At an expense of being a bit more verbose, here, we have 6 panels</p>
<ol>
  <li><strong>Code</strong>: Shows the psudo code of Simple bandit algorithm.</li>
  <li><strong>Bandits</strong>: A visualization of Slot machines. here, instead of 10 arms we have split it into 10 different slot machines for visual clearity.</li>
  <li><strong>Environments</strong>: Since, our Environments are these 10 different slot machines, we have plot the reward distribution as well as mean of each distribution. The Idea that we will react the optimal policy when we estimate the mean of all the distribution as close as possible.</li>
  <li><strong>Current Expected Reward</strong>: As the name suggest, here we plot the expected rewards for all the slot machines at each time step.</li>
  <li><strong>Relative Frequency</strong>: Relative frequency of selecting each slot machine.</li>
  <li><strong>Current Episode</strong>: Plot of current reward sampled from the distribution of current selected slot machine, at each time step.</li>
</ol>

<h2 id="what-is-a-k-armed-bandit-problem">What is a K-armed Bandit Problem?</h2>

<blockquote>
  <p>In K-armed Bandit Problem, You are faced repeatedly with a choice among K-options, or actions. After each choice, you receive a numerical reward chosen from a stationary probability distribution that depends on the action you selected. your objective is to maximize the expected total reward over some time, for example, over 1000 action selections, or time steps.</p>
</blockquote>

<ul>
  <li>
    <p><strong>Value</strong> of that action is the expected reward given that that action is selected</p>

    <script type="math/tex; mode=display">q_{*}(a) \doteq \mathbb{E}\left[R_{t} | A_{t}=a\right]</script>
  </li>
  <li>
    <p>In practice, since we don’t know that exact action value we tend to use the estimated value of action ‘a’ at timestep t as <script type="math/tex">Q_t(a)</script>. And one of our goals is to be as close to <script type="math/tex">q*(a)</script> as possible….</p>
  </li>
  <li>
    <p>Although the agent that only exploit by choosing greedily might perform better than the agent who explores in the initial few steps, it turns out that in the long run, the one who explores performs better because it was able to assess the action that might prove to be much better in the long run whereas the greedy method often gets stuck performing the suboptimal actions… so it’s almost always better to explore.</p>
  </li>
</ul>

<h3 id="action-value-methods">Action-value Methods</h3>

<ul>
  <li>
    <p>The methods for estimating the values of actions for using the estimates to make action selection decisions are collectively known as <strong>action-value methods</strong>…</p>
  </li>
  <li>
    <p>The simplest way of estimating the action values is to just take the sample average:</p>

    <script type="math/tex; mode=display">Q_{t}(a) \doteq \frac{\text { sum of rewards when } a \text { taken prior to } t}{\text { number of times } a \text { taken prior to } t}=\frac{\sum_{i=1}^{t-1} R_{i} \cdot \mathbb{1}_{A_{i}=a}}{\sum_{i=1}^{t-1} \mathbb{1}_{A_{i}=a}}</script>

    <p>Plus, the simplest method of selecting the action is to always act greedily i.e:</p>

    <script type="math/tex; mode=display">A_t = \operatorname{argmax}_{a} Q_t(a)</script>
  </li>
</ul>

<h3 id="10-arm-test-bed">10-arm Test Bed</h3>

<ul>
  <li>
    <p>A better way of action selection would be to behave greedily most of the time, but every once in a while (with a small probability <script type="math/tex">\epsilon</script>, instead select randomly which is the exact reasoning behind the <script type="math/tex">\epsilon</script>-greedy algorithm…</p>

    <p>The advantage of this method is that in the limit, the action value converges to q*(a) for each action because until then it’s been visited infinite amount of time</p>

    <p>This also means that the probability of selecting the optimal action converges to greater than <script type="math/tex">1-\epsilon</script></p>
  </li>
  <li>
    <p>If the reward variance is zero, then the greedy method would know the true value of each action after trying it once. In this case, the greedy method might actually perform best but even in the deterministic case there is still a large advantage to explore because there could be the case where the action value is deterministic but the environment is non-stationary which means it is possible that one of the non-optimal action become optimal over time…</p>
  </li>
  <li>
    <p>So, our original formulation is not suited for incremental learning that we have in the RL setting but with slight modification (see derivation 2.3) we can create our first simple bandit algorithm:-</p>
  </li>
</ul>

<div style="margin: 0 auto; text-align: center">
    <img src="http://localhost:4000/assets/img/posts_imgs/bandits/body/banditAlgo.png" width="80%" />
</div>

<h2 id="further-reading">Further Reading</h2>
<ul>
  <li>https://en.wikipedia.org/wiki/Multi-armed_bandit</li>
  <li>https://www.ualberta.ca/computing-science/graduate-studies/course-directory/courses/bandit-algorithms.html</li>
</ul>

        <div class="page-footer">
          <div class="page-tag">
            <span>Tags:</span>
            
            <a href="/tags#ML" class="tag">| ML</a>
            
            <a href="/tags#AI" class="tag">| AI</a>
            
            <a href="/tags#Reinforcement Learning" class="tag">| Reinforcement Learning</a>
            
            <a href="/tags#RL" class="tag">| RL</a>
            
            <a href="/tags#Bandits" class="tag">| Bandits</a>
            
            <a href="/tags#Arm" class="tag">| Arm</a>
            
            <a href="/tags#Multi-arm" class="tag">| Multi-arm</a>
            
          </div><!-- End Tags -->
          <div class="page-share">
            <span>Share:</span>
            <a href="https://twitter.com/intent/tweet?text=K-Arm Bandits&url=http://localhost:4000/reinforcement/learning/Bandits.html" title="Share on Twitter" rel="nofollow" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
            <a href="https://facebook.com/sharer.php?u=http://localhost:4000/reinforcement/learning/Bandits.html" title="Share on Facebook" rel="nofollow" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
            <a href="https://plus.google.com/share?url=http://localhost:4000/reinforcement/learning/Bandits.html" title="Share on Google+" rel="nofollow" target="_blank"><i class="fa fa-google" aria-hidden="true"></i></a>
          </div><!-- End Share -->
        </div>
        <!-- Removed disqus, newsletter, recent posts -->
        <div class="post-nav">
        <div>
          
          <a href="/reinforcement/learning/monteCarlo.html">&laquo;&nbsp;Monte Carlo</a>
          
        </div>
        <div class="post-nav-next">
          
        </div>
      </div>


      </div>
    </div> <!-- End Wrapper -->
  </article>
  <div class="search-box">
  <div class="wrapper">
    <div class="search-grid">
      <form class="search-form">
        <div id="search-container">
          <input type="text" id="search-input" class="search" placeholder="Search">
        </div>
      </form>
      <ul id="results-container" class="results-search"></ul>
      <div class="icon-close-container">
        <span class="search-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
      </div>
    </div>
  </div>
</div>

  <footer class="main-footer">
  <div class="copyright">
    <p>2021 &copy; <a href="http://localhost:4000"> Reinforcement Learning Playground </a></p>
  </div>
</footer> <!-- End Footer -->

</div>

  <!-- JS -->
<script src="/assets/js/jquery-3.2.1.min.js"></script>
<script src="/assets/js/jekyll-search.js"></script>
<script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a></li>',
    noResultsText: 'No results found',
    fuzzy: false,
    exclude: ['Welcome']
  });
</script>
<script src="/assets/js/main.js"></script>

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
